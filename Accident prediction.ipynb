{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a79dfb-5fb2-4f3c-9810-c9b2885b0049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.22 GiB for an array with shape (1508032, 109) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# SMOTE for class balancing\u001b[39;00m\n\u001b[0;32m     64\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Train a Random Forest\u001b[39;00m\n\u001b[0;32m     68\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:390\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m    389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mkneighbors(X_class, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\n\u001b[0;32m    392\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n\u001b[0;32m    394\u001b[0m y_resampled\u001b[38;5;241m.\u001b[39mappend(y_new)\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:128\u001b[0m, in \u001b[0;36mBaseSMOTE._make_samples\u001b[1;34m(self, X, y_dtype, y_type, nn_data, nn_num, n_samples, step_size, y)\u001b[0m\n\u001b[0;32m    125\u001b[0m rows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor_divide(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    126\u001b[0m cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmod(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 128\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m y_new \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(n_samples, fill_value\u001b[38;5;241m=\u001b[39my_type, dtype\u001b[38;5;241m=\u001b[39my_dtype)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new, y_new\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:195\u001b[0m, in \u001b[0;36mBaseSMOTE._generate_samples\u001b[1;34m(self, X, nn_data, nn_num, rows, cols, steps, y_type, y)\u001b[0m\n\u001b[0;32m    193\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[rows] \u001b[38;5;241m+\u001b[39m steps\u001b[38;5;241m.\u001b[39mmultiply(diffs)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiffs\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.22 GiB for an array with shape (1508032, 109) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"cleaned_traffic_violations.csv\")\n",
    "\n",
    "# Ensure binary target\n",
    "df = df[df['accident'].isin([True, False])]\n",
    "df['accident'] = df['accident'].astype(int)\n",
    "\n",
    "# Encode high-cardinality fields\n",
    "for col in ['make', 'model']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).fillna(\"Unknown\")\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Verified features\n",
    "safe_features = [\n",
    "    'hour', 'month', 'day_of_week',\n",
    "    'gender', 'race', 'driver_state',\n",
    "    'vehicle_type', 'arrest_type',\n",
    "    'belts', 'personal_injury', 'property_damage', 'fatal',\n",
    "    'alcohol', 'commercial_vehicle', 'hazmat',\n",
    "    'make', 'model'\n",
    "]\n",
    "\n",
    "# Filter available features\n",
    "features = [f for f in safe_features if f in df.columns]\n",
    "categorical = ['gender', 'race', 'driver_state', 'vehicle_type', 'arrest_type', 'day_of_week']\n",
    "categorical = [c for c in categorical if c in df.columns]\n",
    "numerical = list(set(features) - set(categorical))\n",
    "\n",
    "# One-hot encode low-cardinality categoricals\n",
    "X_encoded = pd.get_dummies(df[categorical], drop_first=True)\n",
    "X_full = pd.concat([df[numerical], X_encoded], axis=1)\n",
    "y = df['accident']\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Drop completely empty columns in training set\n",
    "X_train = X_train.dropna(axis=1, how='all')\n",
    "X_test = X_test[X_train.columns]  # ensure shape matches\n",
    "\n",
    "# Impute remaining missing values using most frequent values\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE for class balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Train a Random Forest\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3f764-e835-4dbd-b077-ad5d4a1df1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated accident risk: 32.09%\n"
     ]
    }
   ],
   "source": [
    "def predict_accident_risk(input_dict):\n",
    "    df_input = pd.DataFrame([input_dict])\n",
    "    df_input_encoded = pd.get_dummies(df_input)\n",
    "    df_input_encoded = df_input_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
    "    df_imputed = pd.DataFrame(imputer.transform(df_input_encoded), columns=X_train.columns)\n",
    "    df_scaled = scaler.transform(df_imputed)\n",
    "    prob = model.predict_proba(df_scaled)[0][1]\n",
    "    return round(prob * 100, 2)\n",
    "\n",
    "def simplified_accident_risk(user_input):\n",
    "    base = {\n",
    "        'hour': 12,\n",
    "        'month': 6,\n",
    "        'day_of_week': 'Monday',\n",
    "        'gender': 'Male',\n",
    "        'race': 'Unknown',\n",
    "        'driver_state': 'MD',\n",
    "        'vehicle_type': 'PASSENGER CAR',\n",
    "        'arrest_type': 'Citation',\n",
    "        'belts': True,\n",
    "        'personal_injury': False,\n",
    "        'property_damage': True,\n",
    "        'fatal': False,\n",
    "        'alcohol': False,\n",
    "        'commercial_vehicle': False,\n",
    "        'hazmat': False,\n",
    "        'make': 12,\n",
    "        'model': 103\n",
    "    }\n",
    "    base.update(user_input)\n",
    "    return predict_accident_risk(base)\n",
    "\n",
    "simple_input = {\n",
    "    'hour': 18,\n",
    "    'day_of_week': 'Saturday',\n",
    "    'vehicle_type': 'MOTORCYCLE',\n",
    "    'alcohol': True,\n",
    "    'belts': False\n",
    "}\n",
    "\n",
    "likelihood = simplified_accident_risk(simple_input)\n",
    "print(f\"Estimated accident risk: {likelihood}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457cbeb-d687-4c30-8293-f66bac1ee098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
