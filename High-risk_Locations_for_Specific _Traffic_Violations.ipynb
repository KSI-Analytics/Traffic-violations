{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabf331a-4031-4597-b893-9c02e11265fd",
   "metadata": {},
   "source": [
    "Cleaning the dataset\n",
    "\n",
    "Reading the data from the csv and checking to make sure that I am accessing the dataset and identifying the current data types and removing any attributes I do not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8102871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   SeqID Date Of Stop Time Of Stop Agency  \\\n",
      "0   52282e8c-f2e1-4bb5-8509-2d5e4f8da8ca   05/01/2023     23:11:00    MCP   \n",
      "1   9be35886-e00c-49c2-8f27-2f6307696a17   11/25/2023     00:20:00    MCP   \n",
      "2   9be35886-e00c-49c2-8f27-2f6307696a17   11/25/2023     00:20:00    MCP   \n",
      "3   4d37fa99-0df3-4a56-9ba6-692bce894a34   11/26/2023     09:16:00    MCP   \n",
      "4   3a723e9a-5dc0-4bc3-9bd9-4555d6ce0e49   11/25/2023     05:45:00    MCP   \n",
      "5   3a723e9a-5dc0-4bc3-9bd9-4555d6ce0e49   11/25/2023     05:45:00    MCP   \n",
      "6   66273a8e-980e-413e-8928-56447e3be407   11/25/2023     01:21:00    MCP   \n",
      "7   78cdf309-9fe8-46de-892e-19e9b1bafacd   11/25/2023     03:22:00    MCP   \n",
      "8   78cdf309-9fe8-46de-892e-19e9b1bafacd   11/25/2023     03:22:00    MCP   \n",
      "9   1e24ec33-6a13-483f-9fea-0c2cdc5b2a14   11/24/2023     23:25:00    MCP   \n",
      "10  1e24ec33-6a13-483f-9fea-0c2cdc5b2a14   11/24/2023     23:25:00    MCP   \n",
      "11  1e24ec33-6a13-483f-9fea-0c2cdc5b2a14   11/24/2023     23:25:00    MCP   \n",
      "12  1e24ec33-6a13-483f-9fea-0c2cdc5b2a14   11/24/2023     23:25:00    MCP   \n",
      "13  1e24ec33-6a13-483f-9fea-0c2cdc5b2a14   11/24/2023     23:25:00    MCP   \n",
      "14  d2fca5aa-af7e-4294-86d9-78d43254dbd2   11/25/2023     00:47:00    MCP   \n",
      "\n",
      "                                          SubAgency  \\\n",
      "0                       3rd District, Silver Spring   \n",
      "1   6th District, Gaithersburg / Montgomery Village   \n",
      "2   6th District, Gaithersburg / Montgomery Village   \n",
      "3                             4th District, Wheaton   \n",
      "4                             4th District, Wheaton   \n",
      "5                             4th District, Wheaton   \n",
      "6                            2nd District, Bethesda   \n",
      "7                            2nd District, Bethesda   \n",
      "8                            2nd District, Bethesda   \n",
      "9                            2nd District, Bethesda   \n",
      "10                           2nd District, Bethesda   \n",
      "11                           2nd District, Bethesda   \n",
      "12                           2nd District, Bethesda   \n",
      "13                           2nd District, Bethesda   \n",
      "14                           2nd District, Bethesda   \n",
      "\n",
      "                                          Description  \\\n",
      "0     OPERATING UNREGISTERED MOTOR VEHICLE ON HIGHWAY   \n",
      "1   FAILURE TO DISPLAY REGISTRATION CARD UPON DEMA...   \n",
      "2   DISPLAYING EXPIRED REGISTRATION PLATE ISSUED B...   \n",
      "3   DRIVING VEHICLE WHILE UNDER THE INFLUENCE OF A...   \n",
      "4   RECKLESS DRIVING VEHICLE IN WANTON AND WILLFUL...   \n",
      "5   DRIVER FAILURE TO OBEY PROPERLY PLACED TRAFFIC...   \n",
      "6   EXCEEDING POSTED MAXIMUM SPEED LIMIT: 44 MPH I...   \n",
      "7   DRIVER FAILURE TO STOP AT STEADY CIRCULAR RED ...   \n",
      "8   PERSON DRIVING MOTOR VEHICLE ON HIGHWAY OR PUB...   \n",
      "9   FAILURE OF INDIVIDUAL DRIVING ON HIGHWAY TO DI...   \n",
      "10  DRIVING, ATTEMPTING TO DRIVE MOTOR VEHICLE ON ...   \n",
      "11  FAILURE OF MV OPER. DRIVING ON HWY TO BE IN PO...   \n",
      "12  FAILURE OF MV OPER TO PRESENT EVIDENCE OF REQU...   \n",
      "13  OWNER FAILURE TO EXECUTE SECURITY INTEREST INF...   \n",
      "14  DRIVER FAILURE TO OBEY PROPERLY PLACED TRAFFIC...   \n",
      "\n",
      "                                 Location   Latitude  Longitude Accident  ...  \\\n",
      "0        BRIGGS CHANEY RD @ COLUMIBA PIKE   0.000000   0.000000       No  ...   \n",
      "1                GEORGIA AVE / WEISMAN RD  39.052962 -77.051304       No  ...   \n",
      "2                GEORGIA AVE / WEISMAN RD  39.052962 -77.051304       No  ...   \n",
      "3                          3803 WELLER RD  39.058378 -77.049652       No  ...   \n",
      "4   OLNEY LAYTONSVILLE RD @ FIELDCREST RD   0.000000   0.000000       No  ...   \n",
      "5   OLNEY LAYTONSVILLE RD @ FIELDCREST RD   0.000000   0.000000       No  ...   \n",
      "6      S/B GEORGIA AVENUE @ DENNIS AVENUE   0.000000   0.000000       No  ...   \n",
      "7           16 TH STREET @ GEORGIA AVENUE   0.000000   0.000000       No  ...   \n",
      "8           16 TH STREET @ GEORGIA AVENUE   0.000000   0.000000       No  ...   \n",
      "9       UNIVERSITY BLVD W & VEIRS MILL RD  39.041932 -77.058799       No  ...   \n",
      "10      UNIVERSITY BLVD W & VEIRS MILL RD  39.041932 -77.058799       No  ...   \n",
      "11      UNIVERSITY BLVD W & VEIRS MILL RD  39.041932 -77.058799       No  ...   \n",
      "12      UNIVERSITY BLVD W & VEIRS MILL RD  39.041932 -77.058799       No  ...   \n",
      "13      UNIVERSITY BLVD W & VEIRS MILL RD  39.041932 -77.058799       No  ...   \n",
      "14       RANDOLPH RD & ENGLISH ORCHARD CT  39.060892 -77.044710       No  ...   \n",
      "\n",
      "          Charge                 Article Contributed To Accident      Race  \\\n",
      "0     13-401(b1)  Transportation Article                   False     WHITE   \n",
      "1      13-409(b)  Transportation Article                   False  HISPANIC   \n",
      "2      13-411(f)  Transportation Article                   False  HISPANIC   \n",
      "3    21-902(a1i)  Transportation Article                   False  HISPANIC   \n",
      "4    21-901.1(a)  Transportation Article                   False     WHITE   \n",
      "5     21-201(a1)  Transportation Article                   False     WHITE   \n",
      "6       21-801.1  Transportation Article                   False  HISPANIC   \n",
      "7     21-202(h1)  Transportation Article                   False     BLACK   \n",
      "8      16-303(c)  Transportation Article                   False     BLACK   \n",
      "9      16-112(c)  Transportation Article                   False  HISPANIC   \n",
      "10    16-101(a1)  Transportation Article                   False  HISPANIC   \n",
      "11  17-104.2(b1)  Transportation Article                   False  HISPANIC   \n",
      "12  17-104.2(b2)  Transportation Article                   False  HISPANIC   \n",
      "13     13-203(b)  Transportation Article                   False  HISPANIC   \n",
      "14    21-201(a1)  Transportation Article                   False  HISPANIC   \n",
      "\n",
      "   Gender    Driver City Driver State DL State          Arrest Type  \\\n",
      "0       M   GAITHERSBURG           MD       MD    A - Marked Patrol   \n",
      "1       M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "2       M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "3       M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "4       M   GAITHERSBURG           MD       MD    A - Marked Patrol   \n",
      "5       M   GAITHERSBURG           MD       MD    A - Marked Patrol   \n",
      "6       F  SILVER SPRING           MD       MD  B - Unmarked Patrol   \n",
      "7       M         JESSUP           MD       MD  B - Unmarked Patrol   \n",
      "8       M         JESSUP           MD       MD  B - Unmarked Patrol   \n",
      "9       M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "10      M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "11      M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "12      M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "13      M  SILVER SPRING           MD       MD    A - Marked Patrol   \n",
      "14      M         SEVERN           MD       MD    A - Marked Patrol   \n",
      "\n",
      "                              Geolocation  \n",
      "0                              (0.0, 0.0)  \n",
      "1         (39.0529625, -77.0513041666667)  \n",
      "2         (39.0529625, -77.0513041666667)  \n",
      "3   (39.0583783333333, -77.0496516666667)  \n",
      "4                              (0.0, 0.0)  \n",
      "5                              (0.0, 0.0)  \n",
      "6                              (0.0, 0.0)  \n",
      "7                              (0.0, 0.0)  \n",
      "8                              (0.0, 0.0)  \n",
      "9   (39.0419323833333, -77.0587989666667)  \n",
      "10  (39.0419323833333, -77.0587989666667)  \n",
      "11  (39.0419323833333, -77.0587989666667)  \n",
      "12  (39.0419323833333, -77.0587989666667)  \n",
      "13  (39.0419323833333, -77.0587989666667)  \n",
      "14  (39.0608920833333, -77.0447097333333)  \n",
      "\n",
      "[15 rows x 43 columns]\n",
      "\n",
      "\n",
      "Exploring the Data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1996597 entries, 0 to 1996596\n",
      "Data columns (total 43 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   SeqID                    object \n",
      " 1   Date Of Stop             object \n",
      " 2   Time Of Stop             object \n",
      " 3   Agency                   object \n",
      " 4   SubAgency                object \n",
      " 5   Description              object \n",
      " 6   Location                 object \n",
      " 7   Latitude                 float64\n",
      " 8   Longitude                float64\n",
      " 9   Accident                 object \n",
      " 10  Belts                    object \n",
      " 11  Personal Injury          object \n",
      " 12  Property Damage          object \n",
      " 13  Fatal                    object \n",
      " 14  Commercial License       object \n",
      " 15  HAZMAT                   object \n",
      " 16  Commercial Vehicle       object \n",
      " 17  Alcohol                  object \n",
      " 18  Work Zone                object \n",
      " 19  Search Conducted         object \n",
      " 20  Search Disposition       object \n",
      " 21  Search Outcome           object \n",
      " 22  Search Reason            object \n",
      " 23  Search Reason For Stop   object \n",
      " 24  Search Type              object \n",
      " 25  Search Arrest Reason     object \n",
      " 26  State                    object \n",
      " 27  VehicleType              object \n",
      " 28  Year                     float64\n",
      " 29  Make                     object \n",
      " 30  Model                    object \n",
      " 31  Color                    object \n",
      " 32  Violation Type           object \n",
      " 33  Charge                   object \n",
      " 34  Article                  object \n",
      " 35  Contributed To Accident  bool   \n",
      " 36  Race                     object \n",
      " 37  Gender                   object \n",
      " 38  Driver City              object \n",
      " 39  Driver State             object \n",
      " 40  DL State                 object \n",
      " 41  Arrest Type              object \n",
      " 42  Geolocation              object \n",
      "dtypes: bool(1), float64(3), object(39)\n",
      "memory usage: 641.7+ MB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I only want to do this section once\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Reading from the csv & loading the dataframe\n",
    "data = pd.read_csv('Traffic_Violations.csv')\n",
    "\n",
    "#Testing if it read from the csv\n",
    "print(data.head(15)) \n",
    "print('\\n')\n",
    "\n",
    "#Before \n",
    "\n",
    "#Identifying the current data types\n",
    "print(\"Exploring the Data\")\n",
    "print(data.info())\n",
    "print('\\n')\n",
    "\n",
    "#for this feature I only require these attributes [Latitude, Longitude, Accident, Belts, Personal Injury, Property Damage, Fatal, HAZMAT, Alcohol]\n",
    "dropping_these_attributes = [\"SeqID\", \"Date Of Stop\", \"Location\", \"Violation Type,\", \"Time Of Stop\", \"Agency\", \"SubAgency\", \"Description\", \"Commercial License\", \"Commercial Vehicle\", \"Work Zone\", \"Search Conducted\", \"Search Disposition\", \"Search Outcome\", \"Search Reason\", \"Search Reason For Stop\", \"Search Type\", \"Search Arrest Reason\", \"State\", \"VehicleType\", \"Year\", \"Make\", \"Model\", \"Color\", \"Charge\", \"Article\", \"Contributed To Accident\", \"Race\", \"Gender\", \"Driver City\", \"Driver State\", \"DL State\", \"Arrest Type\", \"Geolocation\"]\n",
    "data.drop(columns=dropping_these_attributes, inplace= True, errors= \"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e00cca",
   "metadata": {},
   "source": [
    "For the attributes I did keep, for the categorical attributes I want to check for uniqueness of categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9a1a16f-95a0-4d3d-b164-2fb405762946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Accident Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique Belts Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique Personal Injury Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique Property Damage Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique Fatal Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique HAZMAT Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "Unique Alcohol Values\n",
      "['No' 'Yes']\n",
      "\n",
      "\n",
      "========== Missing Value Counts ==========\n",
      "Latitude           0\n",
      "Longitude          0\n",
      "Accident           0\n",
      "Belts              0\n",
      "Personal Injury    0\n",
      "Property Damage    0\n",
      "Fatal              0\n",
      "HAZMAT             0\n",
      "Alcohol            0\n",
      "Violation Type     0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katoy\\AppData\\Local\\Temp\\ipykernel_23192\\2339732663.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[list_of_yes_no_columns] = data[list_of_yes_no_columns].replace({\"Yes\": 1, \"No\": 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the Data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1996597 entries, 0 to 1996596\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Latitude         float32\n",
      " 1   Longitude        float32\n",
      " 2   Accident         int32  \n",
      " 3   Belts            int32  \n",
      " 4   Personal Injury  int32  \n",
      " 5   Property Damage  int32  \n",
      " 6   Fatal            int32  \n",
      " 7   HAZMAT           int32  \n",
      " 8   Alcohol          int32  \n",
      " 9   Violation Type   object \n",
      "dtypes: float32(2), int32(7), object(1)\n",
      "memory usage: 83.8+ MB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I want to test this section multiple times\n",
    "\n",
    "#Checking the values in my categorical attributes to ensure correct groupings\n",
    "\n",
    "print(\"Unique Accident Values\")\n",
    "print(data[\"Accident\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Unique Belts Values\")\n",
    "print(data[\"Belts\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Unique Personal Injury Values\")\n",
    "print(data[\"Personal Injury\"].unique())\n",
    "print('\\n')\n",
    "\t\n",
    "print(\"Unique Property Damage Values\")\n",
    "print(data[\"Property Damage\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Unique Fatal Values\")\n",
    "print(data[\"Fatal\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Unique HAZMAT Values\")\n",
    "print(data[\"HAZMAT\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Unique Alcohol Values\")\n",
    "print(data[\"Alcohol\"].unique())\n",
    "print('\\n')\n",
    "\n",
    "#Checking for missing fields\n",
    "print('========== Missing Value Counts ==========')\n",
    "print(data.isnull().sum())\n",
    "print('\\n')\n",
    "\n",
    "#converting the yes's and no's to 1's and 0's\n",
    "list_of_yes_no_columns = [\"Accident\", \"Belts\", \"Personal Injury\", \"Property Damage\", \"Fatal\",\"HAZMAT\", \"Alcohol\"]\n",
    "data[list_of_yes_no_columns] = data[list_of_yes_no_columns].replace({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "#casting datatypes and downcasting for reduced memory usage\n",
    "data[list_of_yes_no_columns] = data[list_of_yes_no_columns].astype(\"int32\")\n",
    "\n",
    "lat_long = [\"Latitude\", \"Longitude\"]\n",
    "data[lat_long] = data[lat_long].astype(\"float32\")\n",
    "\n",
    "#After \n",
    "#Testing for changes\n",
    "print(\"Exploring the Data\")\n",
    "print(data.info())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58074397",
   "metadata": {},
   "source": [
    "For the attributes I am using for this feature, there are no missing or duplicate category values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4390399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I only want to do this section once\n",
    "\n",
    "#updating the csv with the changes \n",
    "data.to_csv(\"Traffic_Violations.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cea09",
   "metadata": {},
   "source": [
    "Model 1: Logic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5c2df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ee4fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your location details: Latitude and Longitude \n",
      "\n",
      "Top Most Likely Traffic Violations Based on Location\n",
      "\n",
      "\n",
      "Belts: 1.00\n",
      "Accident: 0.00\n",
      "Personal Injury: 0.00\n",
      "Property Damage: 0.00\n"
     ]
    }
   ],
   "source": [
    "features = [\"Latitude\", \"Longitude\"]\n",
    "violations = [\"Accident\", \"Belts\", \"Personal Injury\", \"Property Damage\", \"Fatal\", \"HAZMAT\",\"Alcohol\"]\n",
    "\n",
    "X = data[features].values\n",
    "y = data[violations].values\n",
    "\n",
    "#Training the model\n",
    "models={}\n",
    "for loc, violation in enumerate(violations):\n",
    "  logr = LogisticRegression(max_iter=1000)\n",
    "  logr.fit(X, y [:, loc])\n",
    "  models[violation] = logr\n",
    "\n",
    "def probability_function (logr, user_input_values):\n",
    "  return logr.predict_proba([user_input_values])[0][1]\n",
    "   \n",
    "\n",
    "#User Inputs\n",
    "print(\"Enter your location details: Latitude and Longitude \\n\")\n",
    "\n",
    "latitude_input_value = float(input(\"Enter your Latitude: \"))\n",
    "longitude_input_value = float(input(\"Enter your Longitude: \"))\n",
    "\n",
    "user_input_values = [latitude_input_value, longitude_input_value]\n",
    "\n",
    "result = []\n",
    "for v in violations:\n",
    "  p = probability_function(models[v], user_input_values)\n",
    "  result.append(p)\n",
    "\n",
    "top_viol = sorted(zip(violations, result), key=lambda p: p[1], reverse=True)[:4]\n",
    "\n",
    "print(\"Top Most Likely Traffic Violations Based on Location\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for vio, prob in top_viol:\n",
    "  print(f\"{vio}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce80ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ead216e4",
   "metadata": {},
   "source": [
    "Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cc05f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa3cd016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your location details: Latitude and Longitude \n",
      "\n",
      "Top Most Likely Traffic Violations Based on Location\n",
      "\n",
      "\n",
      "Personal Injury: 0.50\n",
      "Accident: 0.00\n",
      "Belts: 0.00\n",
      "Property Damage: 0.00\n"
     ]
    }
   ],
   "source": [
    "features = [\"Latitude\", \"Longitude\"]\n",
    "violations = [\"Accident\", \"Belts\", \"Personal Injury\", \"Property Damage\", \"Fatal\", \"HAZMAT\",\"Alcohol\"]\n",
    "\n",
    "X = data[features].values\n",
    "y = data[violations].values\n",
    "\n",
    "#Training the model\n",
    "models={}\n",
    "for loc, violation in enumerate(violations):\n",
    "  rfc = RandomForestClassifier(n_estimators= 10, random_state=5)\n",
    "  rfc.fit(X, y [:, loc])\n",
    "  models[violation] = rfc\n",
    "\n",
    "def probability_function (rfc, user_input_values):\n",
    "  return rfc.predict_proba([user_input_values])[0][1]\n",
    "   \n",
    "\n",
    "#User Inputs\n",
    "print(\"Enter your location details: Latitude and Longitude \\n\")\n",
    "\n",
    "latitude_input_value = float(input(\"Enter your Latitude: \"))\n",
    "longitude_input_value = float(input(\"Enter your Longitude: \"))\n",
    "\n",
    "user_input_values = [latitude_input_value, longitude_input_value]\n",
    "\n",
    "result = []\n",
    "for v in violations:\n",
    "  p = probability_function(models[v], user_input_values)\n",
    "  result.append(p)\n",
    "\n",
    "top_viol = sorted(zip(violations, result), key=lambda p: p[1], reverse=True)[:4]\n",
    "\n",
    "print(\"Top Most Likely Traffic Violations Based on Location\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for vio, prob in top_viol:\n",
    "  print(f\"{vio}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31cdf0",
   "metadata": {},
   "source": [
    "Model 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef1e1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18e010ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your location details: Latitude and Longitude \n",
      "\n",
      "Top Most Likely Traffic Violations Based on Location\n",
      "\n",
      "\n",
      "Accident: 0.03\n",
      "Belts: 0.03\n",
      "Property Damage: 0.02\n",
      "Personal Injury: 0.01\n"
     ]
    }
   ],
   "source": [
    "features = [\"Latitude\", \"Longitude\"]\n",
    "violations = [\"Accident\", \"Belts\", \"Personal Injury\", \"Property Damage\", \"Fatal\", \"HAZMAT\",\"Alcohol\"]\n",
    "\n",
    "X = data[features].values\n",
    "y = data[violations].values\n",
    "\n",
    "#Training the model\n",
    "models={}\n",
    "for loc, violation in enumerate(violations):\n",
    "  gbc = GradientBoostingClassifier(n_estimators= 10, learning_rate=0.2)\n",
    "  gbc.fit(X, y [:, loc])\n",
    "  models[violation] = gbc\n",
    "\n",
    "def probability_function (gbc, user_input_values):\n",
    "  return gbc.predict_proba([user_input_values])[0][1]\n",
    "   \n",
    "\n",
    "#User Inputs\n",
    "print(\"Enter your location details: Latitude and Longitude \\n\")\n",
    "\n",
    "latitude_input_value = float(input(\"Enter your Latitude: \"))\n",
    "longitude_input_value = float(input(\"Enter your Longitude: \"))\n",
    "\n",
    "user_input_values = [latitude_input_value, longitude_input_value]\n",
    "\n",
    "result = []\n",
    "for v in violations:\n",
    "  p = probability_function(models[v], user_input_values)\n",
    "  result.append(p)\n",
    "\n",
    "top_viol = sorted(zip(violations, result), key=lambda p: p[1], reverse=True)[:4]\n",
    "\n",
    "print(\"Top Most Likely Traffic Violations Based on Location\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for vio, prob in top_viol:\n",
    "  print(f\"{vio}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe18fc",
   "metadata": {},
   "source": [
    "Models Accuracy, Mean Absoute Error and Root Mean Squre Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa622fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident\n",
      "Random Forest Classifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[:, v])\n\u001b[0;32m     30\u001b[0m m_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 32\u001b[0m model_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, m_pred)\n\u001b[0;32m     33\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, m_pred)\n\u001b[0;32m     34\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, m_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3, random_state=5)\n",
    "\n",
    "#Setting the models\n",
    "\n",
    "m1= RandomForestClassifier(n_estimators=10, random_state=5)\n",
    "m2= GradientBoostingClassifier(n_estimators=10, learning_rate= 0.2)\n",
    "m3= LogisticRegression(max_iter=10)\n",
    "\n",
    "models_set = {\n",
    "    \"Random Forest Classifier\":m1,\n",
    "    \"Gradient Boosting Classifier\":m2,\n",
    "    \"Logistic Regression\":m3\n",
    "}\n",
    "\n",
    "for v, violation in enumerate(violations):\n",
    "    print(f\"{violation}\")\n",
    "    \n",
    "    for name, model in models_set.items():\n",
    "        print(f\"{name}\")\n",
    "\n",
    "        model.fit(X_train, y_train[:, v])\n",
    "\n",
    "        m_pred = model.predict(X_test)\n",
    "\n",
    "        model_accuracy = accuracy_score(y_test[:, v], m_pred)\n",
    "        mae = mean_absolute_error(y_test[:, v], m_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[:, v], m_pred))\n",
    "\n",
    "        print(f\"Accuracy: {model_accuracy: .2f}\")\n",
    "        print(f\"MAE:{mae: .2f}\")\n",
    "        print(f\"RSME: {rmse: .2f}\")\n",
    "        print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14827f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
